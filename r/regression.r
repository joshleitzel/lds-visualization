# This code is adapted from the regression group's code.

require(lars);
require(lasso2);


"
This project takes in the clusters from the first project, randomly selects 5
clusters, takes the mean of them, and then fits a model to the cluster using
the most efficient/parsimonious number of predictors from the list of TFs.

Functions:
1) main: This is the main function that orchestrates the above description.
This function makes calls to functions 2,3,4,5 and 10.
2) getClusters: after having the connection to the SQLite db in main(), this
function takes 5 random clusters from the database, finds the mean of the
each time point in each cluster, and then returns a list of the 5 vectors
representing the mean of each cluster.
3) tfList: This function loads the transcription factors from the ratios
data frame, and returns a matrix of just the TFs.
4) predictors: This takes in the matrix of TFs generated by tfList, and
retruns the 25 most correlated transcription factors to a given y, which
is the mean of a cluster i that is generated by getClusters.
5) bestFit(): Best fit is the function from homework 5: it returns the
model that has the fewest predictors and is within one standard error
of the best possible error.
*** Helper Functions ***
6) cv.folds(): cv.folds is a cross validation tool that splits the data
7) cv.lm(): cv.lm is a cross validated lm tool
8) plot.cv.lm(): plots the lm
9) predict.from.lm(): predicts from the lm
10)pause(): a simple pause function

"

getClusters <- function(clusnum=1){
	# Randomly selects cluster row numbers
	row.num <- clusnum
  
	# A list of vectors that contain the means of the cluster at each time point
	clusters <- list()
print("rownum");
print(row.num);
	for (i in row.num) {
	  print('yut');
	  print(i);
    sqlcmd <- paste("select * from ba_ratios inner join k173 on ba_ratios.row_names=k173.row_names where out=", i, sep="")
 	  data <- dbGetQuery(sql.clusters, sqlcmd)
    
    print('uyt');
    # This will remove the non-numeric rows
    data<-data[-c(1,53,54)]
	
    # Taking the mean of the cluster and putting it into one vector
    cluster.mean <- as.vector(colMeans(data))
  	clusters <- rbind(clusters,cluster.mean)
  }
  cat("cluster shown: ", row.num, "\n")
  #str(clusters)
  invisible(clusters)

}

# This reads in the tf names and returns a matrix of only the TF values of

tfList <- function(tfNames){
  load("data/baa.ratios.rda")
  miniList <- list()
  for (i in 1:length(tfNames)){
    # as.vector will remove the names so we can work just with the numbers
    miniList[[i]] <- as.vector(ratios[tfNames[i],])
  }
  
  invisible(do.call(rbind,miniList))
}

  
# This returns the 20 most correlated (or anti-correlated b/c TFs can be
# correlated or anti correlated.
predictors <- function(y, tfs) {
  cors <- double()
    
  # Forming the list of correlations for each transcription
	for (i in 1:dim(tfs)[1]) {
		t = tfs[i,]
    tcor = abs(cor(y, t, use="na.or.complete"))
		cors <- append(cors, tcor)
	}
	
  # Like in the slides, taking the top 20 most correlated TFs
  top20 <- tfs[sort(cors, decreasing = T, index.return = T)$ix[1:20],]
	invisible(top20)
}
  
  
# Finds the most parsimonious model of x and y


# **** HELPER FUNCTIONS ****

# Splits the data
cv.folds <- function(n, folds = 10) {
  split(sample(1:n), rep(1:folds, length = n))
}


# Fits a lm to the data using cv
cv.lm <- function( y, x, k= 5, p = 1:dim(x)[2], method = "rss" ) {   
   if ( length(p) < dim(x)[2] ) { 
      x <- as.matrix( x[,p] )
   }   
   cv.subsets <- cv.folds( length(y), folds = k)
   cv.rss <- numeric(k)
   for (i in 1:k) {
   	  tmp.lm <- lm( y[ - cv.subsets[[i]] ] ~ x[ - cv.subsets[[i]],  ] )
   	  y.hat <- predict.from.lm( tmp.lm, x[cv.subsets[[i]],] )                                 
   	  cv.rss[i] <- mean( (y[ cv.subsets[[i]] ] - y.hat )**2 )  
   }	  
   return( list( cv = mean( cv.rss ), cv.err = sqrt( var( cv.rss ) / k ) ) ) 
}	


# Plots the lm
plot.cv.lm <- function (x, cv, cv.err ) {
    plot(x, cv, type = "b", ylim = range(cv, cv + cv.err, cv - cv.err))
    error.bars(x, cv + cv.err, cv - cv.err, width = 1/(1.5* length(x)) )
    invisible() 
}

 
# Predicts from the lm
predict.from.lm <- function( lm1, x) {
     x <- as.matrix( x )
     if (class(lm1) != "lm") {
       stop("input class is not lm")
     	return( FALSE )
     } 
     coeff <- lm1$coefficients
     n <- dim( x )[1]
     tmp.mat <- t( cbind( rep(1,n) , x) ) * coeff
     y.hat <-  apply( tmp.mat, 2, sum)
     invisible( y.hat ) 
}

# A simple  function
pause <- function() {  
  cat("Press <Enter> to continue...")
  readline()
  invisible()
}